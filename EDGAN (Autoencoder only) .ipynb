{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMI/7YKfpFAOIsDLBqZYGA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FAhtisham/Latext-based-EnhancerGAN/blob/main/EDGAN%20(Autoencoder%20only)%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl5jzIcVJ2RA"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY8WmdezJ4kW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "from tqdm import tqdm "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5G0Jf3Yy2d6"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgD6Ac9Ky1bj"
      },
      "source": [
        "class Nucleotides:\n",
        "  def __init__(self, seqs):\n",
        "    self.nuc_pairs= self.make_pairs(seqs)\n",
        "    print(\"total words in vocab\", self.nuc_pairs)\n",
        "    self.encoding= {w:i for i,w in enumerate(self.nuc_pairs,1)}\n",
        "    self.decoding= {i:w for i,w in enumerate(self.nuc_pairs,1)}\n",
        "\n",
        "  \n",
        "  def make_pairs(self, seqs, clip=1):\n",
        "    nuc_pairs= collections.Counter()\n",
        "\n",
        "    for seq in tqdm(seqs):\n",
        "      nuc_pairs.update(seq)\n",
        "\n",
        "    # check why this statement is so important (84, remains same without it)\n",
        "    for nucs in list(nuc_pairs.keys()):\n",
        "      if nuc_pairs[nucs] < clip:\n",
        "        nuc_pairs.pop(nucs)\n",
        "\n",
        "    return list(sorted(nuc_pairs.keys()))\n",
        "\n",
        "\n",
        "  def size(self):\n",
        "    assert len(self.encoding) == len(self.decoding)\n",
        "    return len(self.encoding)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "class Sequences(Dataset):\n",
        "    def __init__(self, seq_len=131):\n",
        "      self.seq_len= seq_len\n",
        "      print(self.seq_len)\n",
        "      self.seqs= self.convert_seqs_to_words(self.load_data())\n",
        "      self.seqs= self.get_size_specific_seqs(self.seqs)\n",
        "      self.nucleotides= Nucleotides(self.seqs)\n",
        "    \n",
        "\n",
        "    def read_fasta(self,fp):\n",
        "        name, seq = None, []\n",
        "        for line in fp:\n",
        "            line = line.rstrip()\n",
        "            if line.startswith(\">\"):\n",
        "                if name: yield (name, ''.join(seq))\n",
        "                name, seq = line, []\n",
        "            else:\n",
        "                seq.append(line)\n",
        "        if name: yield (name, ''.join(seq))\n",
        "    \n",
        "    def load_data(self):\n",
        "      sequences = []\n",
        "      # Reading FASTA file\n",
        "      with open(\"permissive_enhancers\",\"r\") as fp:\n",
        "        for name, seq in self.read_fasta(fp):\n",
        "          sequences.append(seq)\n",
        "      print(\"Sequences Read Succesfully !!!!\")\n",
        "      print(\"Total Raw Sequences: \",len(sequences))\n",
        "      return sequences\n",
        "    \n",
        "    def add_padding(self,seq, p_len):\n",
        "      seq = seq + (\"P\" * p_len)\n",
        "      return seq\n",
        "  \n",
        "  \n",
        "    def convert_seqs_to_words(self,sequences):\n",
        "      f_sequences = []\n",
        "      for i in range(len(sequences)):\n",
        "        temp = \"\"\n",
        "        str_ = sequences[i]\n",
        "        j=0\n",
        "        if len(str_)%3!=0:\n",
        "          n = len(str_)\n",
        "          while n % 3 != 0:\n",
        "            n+=1\n",
        "            str_= self.add_padding(str_,n-len(str_))\n",
        "        for k in range(0,len(str_)):\n",
        "          j+=1\n",
        "          if  j%3==0:\n",
        "            temp = temp + str_[k-2:j] + ' ' \n",
        "          #j+=3\n",
        "        f_sequences.append(temp) \n",
        "      f_sequences= [j.split() for j in f_sequences]\n",
        "      return f_sequences\n",
        "    \n",
        "    def encode(self, seq):\n",
        "      enc= self.nucleotides.encoding\n",
        "      a = np.array([enc.get(c) for c in seq])\n",
        "      return a\n",
        "    \n",
        "    \n",
        "    def get_size_specific_seqs(self, seqs):\n",
        "      final_sequences=[]\n",
        "      for i in range(len(seqs)):\n",
        "        if (len(seqs[i]) == 131):\n",
        "          final_sequences.append(seqs[i])\n",
        "\n",
        "      return final_sequences\n",
        "        \n",
        "    def __len__(self):\n",
        "      return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "      return torch.from_numpy(self.encode(self.seqs[i]))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIruIFws5r5p",
        "outputId": "5abfbed1-d9ec-4736-dab4-a652d90165a2"
      },
      "source": [
        "seq_len=131\n",
        "obj= Sequences(seq_len)\n",
        "print(obj.nucleotides.encoding)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131\n",
            "Sequences Read Succesfully !!!!\n",
            "Total Raw Sequences:  43011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [00:00<00:00, 42119.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total words in vocab ['AAA', 'AAC', 'AAG', 'AAP', 'AAT', 'ACA', 'ACC', 'ACG', 'ACP', 'ACT', 'AGA', 'AGC', 'AGG', 'AGP', 'AGT', 'APP', 'ATA', 'ATC', 'ATG', 'ATP', 'ATT', 'CAA', 'CAC', 'CAG', 'CAP', 'CAT', 'CCA', 'CCC', 'CCG', 'CCP', 'CCT', 'CGA', 'CGC', 'CGG', 'CGP', 'CGT', 'CPP', 'CTA', 'CTC', 'CTG', 'CTP', 'CTT', 'GAA', 'GAC', 'GAG', 'GAP', 'GAT', 'GCA', 'GCC', 'GCG', 'GCP', 'GCT', 'GGA', 'GGC', 'GGG', 'GGP', 'GGT', 'GPP', 'GTA', 'GTC', 'GTG', 'GTP', 'GTT', 'TAA', 'TAC', 'TAG', 'TAP', 'TAT', 'TCA', 'TCC', 'TCG', 'TCP', 'TCT', 'TGA', 'TGC', 'TGG', 'TGP', 'TGT', 'TPP', 'TTA', 'TTC', 'TTG', 'TTT']\n",
            "{'AAA': 1, 'AAC': 2, 'AAG': 3, 'AAP': 4, 'AAT': 5, 'ACA': 6, 'ACC': 7, 'ACG': 8, 'ACP': 9, 'ACT': 10, 'AGA': 11, 'AGC': 12, 'AGG': 13, 'AGP': 14, 'AGT': 15, 'APP': 16, 'ATA': 17, 'ATC': 18, 'ATG': 19, 'ATP': 20, 'ATT': 21, 'CAA': 22, 'CAC': 23, 'CAG': 24, 'CAP': 25, 'CAT': 26, 'CCA': 27, 'CCC': 28, 'CCG': 29, 'CCP': 30, 'CCT': 31, 'CGA': 32, 'CGC': 33, 'CGG': 34, 'CGP': 35, 'CGT': 36, 'CPP': 37, 'CTA': 38, 'CTC': 39, 'CTG': 40, 'CTP': 41, 'CTT': 42, 'GAA': 43, 'GAC': 44, 'GAG': 45, 'GAP': 46, 'GAT': 47, 'GCA': 48, 'GCC': 49, 'GCG': 50, 'GCP': 51, 'GCT': 52, 'GGA': 53, 'GGC': 54, 'GGG': 55, 'GGP': 56, 'GGT': 57, 'GPP': 58, 'GTA': 59, 'GTC': 60, 'GTG': 61, 'GTP': 62, 'GTT': 63, 'TAA': 64, 'TAC': 65, 'TAG': 66, 'TAP': 67, 'TAT': 68, 'TCA': 69, 'TCC': 70, 'TCG': 71, 'TCP': 72, 'TCT': 73, 'TGA': 74, 'TGC': 75, 'TGG': 76, 'TGP': 77, 'TGT': 78, 'TPP': 79, 'TTA': 80, 'TTC': 81, 'TTG': 82, 'TTT': 83}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA7vMe1OlE97"
      },
      "source": [
        "def load(batch_size, seq_len):\n",
        "  data= Sequences(seq_len)\n",
        "  return (DataLoader(data, batch_size, shuffle=True), data.nucleotides)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d7NXbpvfJn-"
      },
      "source": [
        "# Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiPOkzZXKLR2"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, nuc_pair_size, embedding_dims, e_hidden_dims, bottleneck_dims, dec_hidden_dims, seq_length, dropout_size = 0.2):\n",
        "    super().__init__()\n",
        "    nuc_pair_size+=1\n",
        "    self.seq_length= seq_length\n",
        "    # define the vars over here (layers, objects)\n",
        "    self.embedding= nn.Embedding( nuc_pair_size, embedding_dims)\n",
        "    self.rnn1= nn.LSTM(input_size= embedding_dims, hidden_size= e_hidden_dims)\n",
        "    self.fc1= nn.Linear(in_features = e_hidden_dims, out_features= bottleneck_dims)\n",
        "    self.a1= nn.ReLU(True)\n",
        "    self.dropout= nn.Dropout(dropout_size)\n",
        "\n",
        "    self.fc2= nn.Linear(in_features = bottleneck_dims, out_features= d_hidden_dims)\n",
        "    self.rnn2= nn.LSTM(input_size= dec_hidden_dims, hidden_size= d_hidden_dims)\n",
        "    self.fc3= nn.Linear(in_features= d_hidden_dims, out_features= nuc_pair_size)\n",
        "\n",
        "\n",
        "\n",
        "  def encoder(self, x):\n",
        "    x= self.embedding(x).permute(1,0,2)\n",
        "    _,(hidden_states, _)= self.rnn1(x)\n",
        "    lv= self.fc1(hidden_states) # latent vector\n",
        "    lv= self.dropout(lv)\n",
        "    return lv\n",
        "\n",
        "\n",
        "  def decoder(self, lv):\n",
        "    lv= self.fc2(lv)\n",
        "    output, _= self.rnn2(lv.repeat(self.seq_length,1,1),(lv,lv))\n",
        "    output= output.permute(1,0,2)\n",
        "    logits= self.fc3(output)\n",
        "    return logits.transpose(1,2)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    lv= self.encoder(x)\n",
        "    logits= self.decoder(lv)\n",
        "    return (lv.squeeze(), logits)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQfduqOfk97O"
      },
      "source": [
        "# Check the common size among seqs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf0jrZTcm0J7"
      },
      "source": [
        "# for i in range(len(obj.seqs)):\n",
        "#   print(len(obj.seqs[i]))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVyQ5YdfP6HU"
      },
      "source": [
        "# f_sequences = obj.seqs\n",
        "# sizes=[]\n",
        "# for i in range(len(f_sequences)):\n",
        "#   if(len(f_sequences[i]) not in sizes):\n",
        "#     sizes.append(len(f_sequences[i]))\n",
        "\n",
        "\n",
        "# import numpy\n",
        "# a = np.zeros(shape=(len(sizes)))\n",
        "\n",
        "# for i in range(len(f_sequences)):\n",
        "#   for j in range(len(sizes)):\n",
        "#     if (len(f_sequences[i]) == sizes[j]):\n",
        "#       a[j]+=1\n",
        "\n",
        "# print(a, sizes)\n",
        "\n",
        "# final_sequences = []\n",
        "# for i in range(len(f_sequences)):\n",
        "#   if (len(f_sequences[i]) == 131):\n",
        "#     final_sequences.append(f_sequences[i])\n",
        "\n",
        "# print(len(final_sequences))\n",
        "\n"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvzR1pCDfN5N"
      },
      "source": [
        "# Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebZMRjIfSYz"
      },
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "  for i,x in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x = x.to(device)\n",
        "    _, logits= model(x)\n",
        "\n",
        "\n",
        "    loss= criterion(logits, x)\n",
        "    train_loss+=loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if interval > 0 and i % interval ==0:\n",
        "      print(\"epoch: \", epoch, \" batch: \", batch_size*i,\"/\", len(train_loader.dataset), \" loss:\", loss.item())\n",
        "      # print(\"epoch: {} | Batch:{}/{} ({:0.f}%)| Loss:{:.6f}\".format(\n",
        "      #     epoch, batch_size*i, len(train_loader.dataset),\n",
        "      #     100.*(batch_size*i)/len(train_loader.dataset),\n",
        "      #     loss.item\n",
        "        \n",
        "      # ))\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  print('(Train) Epoch: {}|loss{:.4f}'.format(epoch, train_loss))\n",
        "  return train_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjOh6ru2spCb",
        "outputId": "db4a4dd2-8af0-4dcc-ccc9-272909dd476b"
      },
      "source": [
        "'''\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--seed\", type=int, default=0)\n",
        "parser.add_argument(\"--epochs\", type=int, default=10)\n",
        "parser.add_argument(\"--batch-size\", type=int, default=32)\n",
        "parser.add_argument(\"--lr\", type=float, default=5e-4)\n",
        "parser.add_argument(\"--dropout\", type=int, default=0.2)\n",
        "parser.add_argument(\"--embedding-dim\", type=int, default=200)\n",
        "parser.add_argument(\"e-hidden-dim\", type=int, default=100)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "print(args)\n",
        "'''\n",
        "\n",
        "seed= 0\n",
        "epochs= 15\n",
        "batch_size= 32\n",
        "lr= 5e-04\n",
        "dropout= 0.2\n",
        "embedding_dims=200\n",
        "e_hidden_dims= 100\n",
        "d_hidden_dims=600\n",
        "seq_length= 131\n",
        "bottleneck_dims=200\n",
        "interval=10\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_loader, nuc_pairs= load(batch_size, seq_length)\n",
        "model = Autoencoder( nuc_pairs.size(), embedding_dims, e_hidden_dims, bottleneck_dims, d_hidden_dims, seq_length, dropout).to(device)\n",
        "\n",
        "\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer= optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131\n",
            "Sequences Read Succesfully !!!!\n",
            "Total Raw Sequences:  43011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [00:00<00:00, 45964.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total words in vocab ['AAA', 'AAC', 'AAG', 'AAP', 'AAT', 'ACA', 'ACC', 'ACG', 'ACP', 'ACT', 'AGA', 'AGC', 'AGG', 'AGP', 'AGT', 'APP', 'ATA', 'ATC', 'ATG', 'ATP', 'ATT', 'CAA', 'CAC', 'CAG', 'CAP', 'CAT', 'CCA', 'CCC', 'CCG', 'CCP', 'CCT', 'CGA', 'CGC', 'CGG', 'CGP', 'CGT', 'CPP', 'CTA', 'CTC', 'CTG', 'CTP', 'CTT', 'GAA', 'GAC', 'GAG', 'GAP', 'GAT', 'GCA', 'GCC', 'GCG', 'GCP', 'GCT', 'GGA', 'GGC', 'GGG', 'GGP', 'GGT', 'GPP', 'GTA', 'GTC', 'GTG', 'GTP', 'GTT', 'TAA', 'TAC', 'TAG', 'TAP', 'TAT', 'TCA', 'TCC', 'TCG', 'TCP', 'TCT', 'TGA', 'TGC', 'TGG', 'TGP', 'TGT', 'TPP', 'TTA', 'TTC', 'TTG', 'TTT']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY28NjRNVXht",
        "outputId": "dbb88121-88d7-4adc-de44-841c97e675f0"
      },
      "source": [
        "model"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (embedding): Embedding(84, 200)\n",
              "  (rnn1): LSTM(200, 100)\n",
              "  (fc1): Linear(in_features=100, out_features=200, bias=True)\n",
              "  (a1): ReLU(inplace=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc2): Linear(in_features=200, out_features=600, bias=True)\n",
              "  (rnn2): LSTM(600, 600)\n",
              "  (fc3): Linear(in_features=600, out_features=84, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "DeXWHtnTglEs",
        "outputId": "19e003ac-d61c-4a66-e095-d4d39ebc9c46"
      },
      "source": [
        "best_loss = 0\n",
        "for epoch in range(epochs):\n",
        "  loss = train(epoch)\n",
        "  if loss < best_loss:\n",
        "      best_loss= loss\n",
        "      print('saved')\n",
        "      torch.save(model.state_dict(), 'ae.th')"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-0f837edadcf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mbest_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-166-b2c44634648d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-163-88dc4de1b047>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mlv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-163-88dc4de1b047>\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, lv)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw79iYNILQEn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLZGbklQLRI2"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1akvR7-LRzL"
      },
      "source": [
        "# Practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLev8oLdVwdV",
        "outputId": "ba6f03e8-2136-4e58-a3cb-ba217ba99b13"
      },
      "source": [
        "arr = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "arr.size()\n",
        "arr = arr.permute(1,0)\n",
        "arr.size()\n",
        "arr"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 5],\n",
              "        [2, 4, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM_z0VHGXWTl",
        "outputId": "b036b149-ebbb-48b8-e2b0-712f97eb516e"
      },
      "source": [
        "arr2 = torch.randn(3,5,2)\n",
        "print(arr2.size())\n",
        "print(arr2)\n",
        "arr2= arr2.permute(2,0,1)\n",
        "print(arr2.size())\n",
        "print(arr2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5, 2])\n",
            "tensor([[[ 0.2006,  1.8473],\n",
            "         [ 0.1055, -1.1586],\n",
            "         [ 0.1208,  0.3094],\n",
            "         [-0.0632, -0.5114],\n",
            "         [ 0.2881,  1.3463]],\n",
            "\n",
            "        [[-0.3929,  1.1025],\n",
            "         [ 1.2375,  0.4721],\n",
            "         [-0.2026,  0.5434],\n",
            "         [-0.2871, -0.9966],\n",
            "         [-0.8792, -0.4815]],\n",
            "\n",
            "        [[-1.4430, -0.9805],\n",
            "         [ 0.2667,  0.6952],\n",
            "         [-0.1730, -1.1442],\n",
            "         [ 0.8840,  0.5541],\n",
            "         [-0.0819, -0.5837]]])\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[ 0.2006,  0.1055,  0.1208, -0.0632,  0.2881],\n",
            "         [-0.3929,  1.2375, -0.2026, -0.2871, -0.8792],\n",
            "         [-1.4430,  0.2667, -0.1730,  0.8840, -0.0819]],\n",
            "\n",
            "        [[ 1.8473, -1.1586,  0.3094, -0.5114,  1.3463],\n",
            "         [ 1.1025,  0.4721,  0.5434, -0.9966, -0.4815],\n",
            "         [-0.9805,  0.6952, -1.1442,  0.5541, -0.5837]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4woNB6ZmvF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}