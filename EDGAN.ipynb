{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Rl5jzIcVJ2RA"
      ],
      "authorship_tag": "ABX9TyMl8CH9Q4KSatpUBG1XXQt6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FAhtisham/Latext-based-EnhancerGAN/blob/main/EDGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl5jzIcVJ2RA"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY8WmdezJ4kW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "from tqdm import tqdm "
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFqya-_9J54x"
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T40Jkdu3JjaX"
      },
      "source": [
        "def read_fasta( fp):\n",
        "        name, seq = None, []\n",
        "        for line in fp:\n",
        "            line = line.rstrip()\n",
        "            if line.startswith(\">\"):\n",
        "                if name: yield (name, ''.join(seq))\n",
        "                name, seq = line, []\n",
        "            else:\n",
        "                seq.append(line)\n",
        "        if name: yield (name, ''.join(seq))\n",
        "\n",
        "\n",
        "\n",
        "def load_data():\n",
        "        sequences = []\n",
        "        # Reading FASTA file\n",
        "        with open(\"permissive_enhancers\",\"r\") as fp:\n",
        "            for name, seq in read_fasta(fp):\n",
        "                sequences.append(seq)\n",
        "            print(\"Sequences Read Succesfully !!!!\")\n",
        "        print(\"Total Raw Sequences: \",len(sequences))\n",
        "        return sequences\n",
        "\n",
        "def add_padding(seq, p_len):\n",
        "  seq = seq + (\"P\" * p_len)\n",
        "  return seq\n",
        "  \n",
        "\n",
        "def convert_seqs_to_words(sequences):\n",
        "  f_sequences = []\n",
        "  for i in range(len(sequences)):\n",
        "    temp = \"\"\n",
        "    str_ = sequences[i]\n",
        "    j=0\n",
        "\n",
        "    if len(str_)%3!=0:\n",
        "      n = len(str_)\n",
        "      while n % 3 != 0:\n",
        "        n+=1\n",
        "      str_= add_padding(str_,n-len(str_))\n",
        "\n",
        "    for k in range(0,len(str_)):\n",
        "      j+=1\n",
        "      if  j%3==0:\n",
        "        temp = temp + str_[k-2:j] + ' ' \n",
        "        #j+=3\n",
        "    f_sequences.append(temp) \n",
        "  f_sequences= [j.split() for j in f_sequences]\n",
        "  return f_sequences"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xXCqBLyKEHv",
        "outputId": "f78fecc4-83ed-46c9-ec0a-179e9fcc5424"
      },
      "source": [
        "f_sequences = convert_seqs_to_words(load_data())\n",
        "print(\"Total Processed Sequences: \",len(f_sequences))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences Read Succesfully !!!!\n",
            "Total Raw Sequences:  43011\n",
            "Total Processed Sequences:  43011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgTvO8tZ6FCi",
        "outputId": "e722ca6d-49f7-4c33-85a4-f0e71cc2e6b4"
      },
      "source": [
        "len(f_sequences)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5G0Jf3Yy2d6"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgD6Ac9Ky1bj"
      },
      "source": [
        "class Nucleotides:\n",
        "  def __init__(self, seqs):\n",
        "    self.nuc_pairs= self.make_pairs(seqs)\n",
        "    self.encoding= {w:i for i,w in enumerate(self.nuc_pairs,1)}\n",
        "    self.decoding= {i:w for i,w in enumerate(self.nuc_pairs,1)}\n",
        "\n",
        "  #def \n",
        "  def make_pairs(self, seqs, clip=1):\n",
        "    nuc_pairs= collections.Counter()\n",
        "\n",
        "    for seq in tqdm(seqs):\n",
        "      nuc_pairs.update(seq)\n",
        "\n",
        "    # check why this statement is so important (84, remains same without it)\n",
        "    for nucs in list(nuc_pairs.keys()):\n",
        "      if nuc_pairs[nucs] < clip:\n",
        "        nuc_pairs.pop(nucs)\n",
        "\n",
        "    return list(sorted(nuc_pairs.keys()))\n",
        "  \n",
        "\n",
        "\n",
        "class Sequences(Dataset):\n",
        "  def __init__(self):\n",
        "    print(\"done\")\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIruIFws5r5p",
        "outputId": "0709a07a-177e-47dc-ea63-a9d4899bb0ce"
      },
      "source": [
        "nuc_pairs = Nucleotides(f_sequences).nuc_pairs\n",
        "print(words, \"\\n\", len(words))\n",
        "encoding = Nucleotides(f_sequences).encoding\n",
        "print(encoding)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 43011/43011 [00:00<00:00, 95632.28it/s]\n",
            " 21%|██        | 9000/43011 [00:00<00:00, 89998.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['AAA', 'AAC', 'AAG', 'AAP', 'AAT', 'ACA', 'ACC', 'ACG', 'ACP', 'ACT', 'AGA', 'AGC', 'AGG', 'AGP', 'AGT', 'APP', 'ATA', 'ATC', 'ATG', 'ATP', 'ATT', 'CAA', 'CAC', 'CAG', 'CAP', 'CAT', 'CCA', 'CCC', 'CCG', 'CCP', 'CCT', 'CGA', 'CGC', 'CGG', 'CGP', 'CGT', 'CPP', 'CTA', 'CTC', 'CTG', 'CTP', 'CTT', 'GAA', 'GAC', 'GAG', 'GAP', 'GAT', 'GCA', 'GCC', 'GCG', 'GCP', 'GCT', 'GGA', 'GGC', 'GGG', 'GGP', 'GGT', 'GPP', 'GTA', 'GTC', 'GTG', 'GTP', 'GTT', 'TAA', 'TAC', 'TAG', 'TAP', 'TAT', 'TCA', 'TCC', 'TCG', 'TCP', 'TCT', 'TGA', 'TGC', 'TGG', 'TGP', 'TGT', 'TPP', 'TTA', 'TTC', 'TTG', 'TTP', 'TTT'] \n",
            " 84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 43011/43011 [00:00<00:00, 92089.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'AAA': 1, 'AAC': 2, 'AAG': 3, 'AAP': 4, 'AAT': 5, 'ACA': 6, 'ACC': 7, 'ACG': 8, 'ACP': 9, 'ACT': 10, 'AGA': 11, 'AGC': 12, 'AGG': 13, 'AGP': 14, 'AGT': 15, 'APP': 16, 'ATA': 17, 'ATC': 18, 'ATG': 19, 'ATP': 20, 'ATT': 21, 'CAA': 22, 'CAC': 23, 'CAG': 24, 'CAP': 25, 'CAT': 26, 'CCA': 27, 'CCC': 28, 'CCG': 29, 'CCP': 30, 'CCT': 31, 'CGA': 32, 'CGC': 33, 'CGG': 34, 'CGP': 35, 'CGT': 36, 'CPP': 37, 'CTA': 38, 'CTC': 39, 'CTG': 40, 'CTP': 41, 'CTT': 42, 'GAA': 43, 'GAC': 44, 'GAG': 45, 'GAP': 46, 'GAT': 47, 'GCA': 48, 'GCC': 49, 'GCG': 50, 'GCP': 51, 'GCT': 52, 'GGA': 53, 'GGC': 54, 'GGG': 55, 'GGP': 56, 'GGT': 57, 'GPP': 58, 'GTA': 59, 'GTC': 60, 'GTG': 61, 'GTP': 62, 'GTT': 63, 'TAA': 64, 'TAC': 65, 'TAG': 66, 'TAP': 67, 'TAT': 68, 'TCA': 69, 'TCC': 70, 'TCG': 71, 'TCP': 72, 'TCT': 73, 'TGA': 74, 'TGC': 75, 'TGG': 76, 'TGP': 77, 'TGT': 78, 'TPP': 79, 'TTA': 80, 'TTC': 81, 'TTG': 82, 'TTP': 83, 'TTT': 84}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d7NXbpvfJn-"
      },
      "source": [
        "# Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiPOkzZXKLR2"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, nuc_pair_size, embedding_dims, e_hidden_dims, bottleneck_dims, dec_hidden_dims, dropout_size = 0.2):\n",
        "    super().__init__()\n",
        "    \n",
        "    # define the vars over here (layers, objects)\n",
        "    self.embedding= nn.Embedding(num_embeddings= nuc_pair_size, embedding_dim= embedding_dims)\n",
        "    self.rnn1= nn.LSTM(input_size= embedding_dims, hidden_size= e_hidden_dims)\n",
        "    self.fc1= nn.Linear(input= e_hidden_dims, out_features= bottleneck_dims)\n",
        "    self.a1= nn.ReLU(True)\n",
        "    self.dropout= nn.Dropout(dropout_size)\n",
        "\n",
        "    self.fc2= nn.Linear(input= bottleneck_dims, output_features= d_hidden_dims)\n",
        "    self.rnn2= nn.LSTM(input_size= dec_hidden_dims, hidden_size= d_hidden_dims)\n",
        "    self.fc3= nn.Linear(input= d_hidden_dims, output_features= nuc_pair_size)\n",
        "\n",
        "\n",
        "\n",
        "  def encoder(self, x):\n",
        "    x= self.embedding(x)\n",
        "    _,(hidden_states, _)= self.rnn1(x)\n",
        "    lv= self.fc1(x) # latent vector\n",
        "    lv= self.Dropout(lv)\n",
        "    return lv\n",
        "\n",
        "\n",
        "  def decoder(self, lv):\n",
        "    lv= self.fc2(lv)\n",
        "    output, _= self.rnn2(lv)\n",
        "    logits= self.fc3(output)\n",
        "    return logits\n",
        "  \n",
        "  def forward(self,x):\n",
        "    lv= self.encoder(x)\n",
        "    logits= self.decoder(lv)\n",
        "    return (lv.squeeze(), logits)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqlB79vJLdne"
      },
      "source": [
        "def load(batch_size, seq_len):\n",
        "    return (DataLoader(f_sequences, batch_size, shuffle=True), nuc_pairs)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvzR1pCDfN5N"
      },
      "source": [
        "# Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebZMRjIfSYz"
      },
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "  for i,x in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    x = x.to(device)\n",
        "    _, logits= model(x)\n",
        "    loss= criterion(logits, x)\n",
        "    train_loss+=loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if args.interval > 0 and i % interval ==0:\n",
        "      print(\"epoch: {} | Batch:{}/{} ({:0.f}%)| Loss:{:.6f}\".format(\n",
        "          epoch, args.batch_size*i, len(train_loader.dataset),\n",
        "          100.*(args.batch_size*i)/len(train_loader.dataset),\n",
        "          loss.item\n",
        "        \n",
        "      ))\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  print('(Train) Epoch: {}|loss{:.4f}'.format(epoch, train_loss))\n",
        "  return train_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjOh6ru2spCb"
      },
      "source": [
        "'''\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--seed\", type=int, default=0)\n",
        "parser.add_argument(\"--epochs\", type=int, default=10)\n",
        "parser.add_argument(\"--batch-size\", type=int, default=32)\n",
        "parser.add_argument(\"--lr\", type=float, default=5e-4)\n",
        "parser.add_argument(\"--dropout\", type=int, default=0.2)\n",
        "parser.add_argument(\"--embedding-dim\", type=int, default=200)\n",
        "parser.add_argument(\"e-hidden-dim\", type=int, default=100)\n",
        "args = parser.parse_args()\n",
        "\n",
        "print(args)\n",
        "'''\n",
        "\n",
        "seed= 0\n",
        "spochs= 5\n",
        "batch_size= 32\n",
        "lr= 5e-04\n",
        "dropout= 0.2\n",
        "embedding_dim=200\n",
        "e_hidden_dims= 1\n",
        "d_hidden_dims=600\n",
        "seq_length= 951\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_loader, nuc_pairs= load(batch_size, seq_length)\n",
        "model = Autoencoder( nuc_pair_size, embedding_dims, e_hidden_dims, bottleneck_dims, dec_hidden_dims, dropout_size = 0.2)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "DeXWHtnTglEs",
        "outputId": "44419c94-fb39-4f71-b31a-203f8064d723"
      },
      "source": [
        ""
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-f873f812ec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 5 required positional arguments: 'nuc_pair_size', 'embedding_dims', 'e_hidden_dims', 'bottleneck_dims', and 'dec_hidden_dims'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw79iYNILQEn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLZGbklQLRI2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1akvR7-LRzL"
      },
      "source": [
        "# Practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLev8oLdVwdV",
        "outputId": "ba6f03e8-2136-4e58-a3cb-ba217ba99b13"
      },
      "source": [
        "arr = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "arr.size()\n",
        "arr = arr.permute(1,0)\n",
        "arr.size()\n",
        "arr"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 5],\n",
              "        [2, 4, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM_z0VHGXWTl",
        "outputId": "b036b149-ebbb-48b8-e2b0-712f97eb516e"
      },
      "source": [
        "arr2 = torch.randn(3,5,2)\n",
        "print(arr2.size())\n",
        "print(arr2)\n",
        "arr2= arr2.permute(2,0,1)\n",
        "print(arr2.size())\n",
        "print(arr2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5, 2])\n",
            "tensor([[[ 0.2006,  1.8473],\n",
            "         [ 0.1055, -1.1586],\n",
            "         [ 0.1208,  0.3094],\n",
            "         [-0.0632, -0.5114],\n",
            "         [ 0.2881,  1.3463]],\n",
            "\n",
            "        [[-0.3929,  1.1025],\n",
            "         [ 1.2375,  0.4721],\n",
            "         [-0.2026,  0.5434],\n",
            "         [-0.2871, -0.9966],\n",
            "         [-0.8792, -0.4815]],\n",
            "\n",
            "        [[-1.4430, -0.9805],\n",
            "         [ 0.2667,  0.6952],\n",
            "         [-0.1730, -1.1442],\n",
            "         [ 0.8840,  0.5541],\n",
            "         [-0.0819, -0.5837]]])\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[ 0.2006,  0.1055,  0.1208, -0.0632,  0.2881],\n",
            "         [-0.3929,  1.2375, -0.2026, -0.2871, -0.8792],\n",
            "         [-1.4430,  0.2667, -0.1730,  0.8840, -0.0819]],\n",
            "\n",
            "        [[ 1.8473, -1.1586,  0.3094, -0.5114,  1.3463],\n",
            "         [ 1.1025,  0.4721,  0.5434, -0.9966, -0.4815],\n",
            "         [-0.9805,  0.6952, -1.1442,  0.5541, -0.5837]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4woNB6ZmvF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}